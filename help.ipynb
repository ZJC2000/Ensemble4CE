{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UnityPath = '/home/data02/zjc/abaw/dataset/Unity'\n",
    "for split in ['train', 'val']:\n",
    "    for emo in ['Neutral', 'Happiness', 'Sadness', 'Surprise', 'Fear', 'Disgust', 'Anger', 'Contempt']:\n",
    "        os.makedirs(os.path.join(f'dataset/Unity/{split}', emo), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAF-DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rafidx2emo = {1: 'Surprise', 2: 'Fear',3: 'Disgust',4: 'Happiness',5: 'Sadness', 6: 'Anger' , 7: 'Neutral'}\n",
    "rafemo2idx = {emo: idx for idx, emo in rafidx2emo.items()}\n",
    "print(rafidx2emo)\n",
    "print(rafemo2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/RAFDB/basic/EmoLabel/list_patition_label.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "rafdb_name2idx = {}\n",
    "for line in lines:\n",
    "    name, idx = line.strip().split()\n",
    "    name = name[:-4] + '_aligned.jpg'\n",
    "    rafdb_name2idx[name] = int(idx)\n",
    "\n",
    "# rafdb_name2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rafdbpath = '/home/data02/zjc/abaw/dataset/RAFDB'\n",
    "\n",
    "\n",
    "imgs = os.listdir(os.path.join(rafdbpath, 'basic/Image/aligned'))\n",
    "for img in tqdm(imgs):\n",
    "    # print(img, rafdb_name2idx[img])\n",
    "    emotype = rafidx2emo[rafdb_name2idx[img]]\n",
    "\n",
    "    img_org_path = os.path.join(rafdbpath, 'basic/Image/aligned', img)\n",
    "\n",
    "    if img.startswith('train'):\n",
    "        img_save_path = os.path.join(UnityPath, 'train', emotype, f'rafdb_{img}')\n",
    "    elif img.startswith('test'):\n",
    "        img_save_path = os.path.join(UnityPath, 'val', emotype, f'rafdb_{img}')\n",
    "    # print(img_org_path)\n",
    "    # print(img_save_path)\n",
    "    \n",
    "    shutil.copyfile(img_org_path, img_save_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 复合表情"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rafdbpath = '/home/data02/zjc/abaw/dataset/RAFDB'\n",
    "cepath = '/home/data02/zjc/abaw/dataset/RAFDBCE7'\n",
    "\n",
    "ceidx2emo = {1: 'Happily Surprised', 2: 'Happily Disgusted',3: 'Sadly Fearful',4: 'Sadly Angry',\n",
    "             5: 'Sadly Surprised',6: 'Sadly Disgusted',7: 'Fearfully Angry',8: 'Fearfully Surprised',\n",
    "             9: 'Angrily Surprised',10: 'Angrily Disgusted',11: 'Disgustedly Surprised'}\n",
    "\n",
    "ceemo2idx = {emo:idx for idx, emo in ceidx2emo.items()}\n",
    "need = [8,1,5,11,9,3,4]\n",
    "# need = range(1, 12)\n",
    "\n",
    "name2idx = {}\n",
    "for emo in ceidx2emo.values():\n",
    "    if ceemo2idx[emo] in need:\n",
    "        os.makedirs(os.path.join('dataset/RAFDBCE7', 'train', emo), exist_ok=True)\n",
    "        os.makedirs(os.path.join('dataset/RAFDBCE7', 'val', emo), exist_ok=True)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "\n",
    "with open('dataset/RAFDB/compound/EmoLabel/list_patition_label.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    name, idx = line.strip().split(' ')\n",
    "    name2idx[name[:-4] + '_aligned.jpg'] = int(idx)\n",
    "\n",
    "# print(name2idx)\n",
    "\n",
    "imgs = os.listdir(os.path.join(rafdbpath, 'compound/Image/aligned'))\n",
    "\n",
    "\n",
    "for img in tqdm(imgs):\n",
    "    # print(img, name2idx[img])\n",
    "    \n",
    "    emotype = ceidx2emo[name2idx[img]]\n",
    "    if name2idx[img] not in need:\n",
    "        continue\n",
    "\n",
    "    # break\n",
    "    img_org_path = os.path.join(rafdbpath, 'compound/Image/aligned', img)\n",
    "\n",
    "    if img.startswith('train'):\n",
    "        img_save_path = os.path.join(cepath, 'train', emotype, f'rafdb_{img}')\n",
    "    elif img.startswith('test'):\n",
    "        img_save_path = os.path.join(cepath, 'val', emotype, f'rafdb_{img}')\n",
    "    # print(img_org_path)\n",
    "    # print(img_save_path)\n",
    "    \n",
    "    shutil.copyfile(img_org_path, img_save_path)\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "len(os.listdir('/home/data02/zjc/abaw/dataset/MAFW/data/clips'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAFW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AffectNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = set()\n",
    "exps = glob(os.path.join('dataset/AffectNet/val_set/annotations', '*_exp.npy'))\n",
    "labels = set(np.load(i).item() for i in exps) # 0, ... ,7\n",
    "affect_idx2emo = {0: 'Neutral', 1: 'Happiness', 2: 'Sadness', 3:'Surprise', 4: 'Fear', 5: 'Disgust', 6: 'Anger', 7: 'Contempt'}\n",
    "affect_emo2idx = {emo: idx for idx, emo in affect_idx2emo.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affectnetpath = '/home/data02/zjc/abaw/dataset/AffectNet'\n",
    "UnityPath = '/home/data02/zjc/abaw/dataset/Unity'\n",
    "\n",
    "\n",
    "\n",
    "for split in os.listdir(affectnetpath):\n",
    "    if split.endswith('.tar'):\n",
    "        continue\n",
    "\n",
    "    split_path = os.path.join(affectnetpath, split)\n",
    "    split_path_imgs = os.path.join(split_path, 'images')\n",
    "\n",
    "    for img in tqdm(os.listdir(split_path_imgs)):\n",
    "        img_org_path = os.path.join(split_path_imgs, img)\n",
    "        emo = int(np.load(os.path.join(split_path, 'annotations', img[:-4] + '_exp.npy')).item())\n",
    "        emotype = affect_idx2emo[emo]\n",
    "        img_save_path = os.path.join(UnityPath, split[:-4], emotype, f'affectnet_{img}')\n",
    "        shutil.copyfile(img_org_path, img_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAFW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mafw = '/home/data/zjc/code/MER2023-Baseline/abaw'\n",
    "print(os.listdir(mafw))\n",
    "np.load(os.path.join(mafw, 'models--facebook--wav2vec2-base-960h-FRA', '00019.npy')).shape\n",
    "np.load(os.path.join(mafw, 'models--facebook--hubert-base-ls960-FRA', '00019.npy')).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpath = 'dataset/MAFW/Train & Test Set/compound/no_caption'\n",
    "res = {}\n",
    "for set_id in os.listdir(mpath):\n",
    "    # print(set_id)\n",
    "    with open(os.path.join(mpath, set_id, 'train.txt')) as f:\n",
    "        lines = f.readlines()\n",
    "    res[f'{set_id}_train'] = {line.strip().split()[0]: line.strip().split()[1] for line in lines}\n",
    "    with open(os.path.join(mpath, set_id, 'test.txt')) as f:\n",
    "        lines = f.readlines()\n",
    "    res[f'{set_id}_test'] = {line.strip().split()[0]: line.strip().split()[1] for line in lines}\n",
    "\n",
    "l = []\n",
    "for set_id in res:\n",
    "    l.append(len(res[set_id]))\n",
    "print(l)\n",
    "\n",
    "for i in range(0, 10, 2):\n",
    "    print(l[i] + l[i+1])\n",
    "\n",
    "mafw = 'dataset/MAFW'\n",
    "frames = os.path.join(mafw, 'data', 'frames/frames')\n",
    "len(os.listdir(frames)), len(os.listdir('/home/data/zjc/code/MER2023-Baseline/abaw/audio'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = {}\n",
    "set1.update(res['set_1_train'])\n",
    "set1.update(res['set_1_test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed = ['fear_surprise', 'fear_surprise_anxiety', \n",
    "          'happiness_surprise',\n",
    "            'sadness_surprise', \n",
    "           'disgust_surprise',\n",
    "            'anger_surprise', \n",
    "            'fear_sadness', 'fear_sadness_anxiety',\n",
    "           'anger_sadness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clip in list(set1.keys()):\n",
    "    if set1[clip] not in needed:\n",
    "        set1.pop(clip)\n",
    "\n",
    "mafwanno = {k[:-4]:v  for k, v in set1.items()}\n",
    "\n",
    "save = {'train':[], 'test':[]}\n",
    "\n",
    "for clip, emo in set1.items():\n",
    "    if clip in res['set_1_train']:\n",
    "        if emo not in ['fear_surprise_anxiety', 'fear_sadness_anxiety']:\n",
    "            save['train'].append({'clip':clip[:-4], 'emo':emo})\n",
    "        else:\n",
    "            save['train'].append({'clip':clip[:-4], 'emo':emo[:-8]})\n",
    "        \n",
    "    elif clip in res['set_1_test']:\n",
    "        if emo not in ['fear_surprise_anxiety', 'fear_sadness_anxiety']:\n",
    "            save['test'].append({'clip':clip[:-4], 'emo':emo})\n",
    "        else:\n",
    "            save['test'].append({'clip':clip[:-4], 'emo':emo[:-8]})\n",
    "    else:\n",
    "        raise KeyError\n",
    "\n",
    "np.save('mafwanno.npy', save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = 'dataset/MAFW/data/frames/frames'\n",
    "\n",
    "for k in set1.keys():\n",
    "    org = os.path.join(ff, k[:-4])\n",
    "    new = os.path.join('dataset/MAFW_need', k[:-4])\n",
    "    shutil.copytree(org, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.load('mafwanno.npy', allow_pickle=True).item()['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "emoclip = defaultdict(list)\n",
    "for k, v in set1.items():\n",
    "    emoclip[v].append(k)\n",
    "emoclip['fear_surprise'].extend(emoclip['fear_surprise_anxiety'])\n",
    "emoclip.pop('fear_surprise_anxiety')\n",
    "emoclip['fear_sadness'].extend(emoclip['fear_sadness_anxiety'])\n",
    "emoclip.pop('fear_sadness_anxiety')\n",
    "\n",
    "for k, v in emoclip.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mafwce = '/home/data02/zjc/abaw/dataset/MAFWCE'\n",
    "frame_path = '/home/data02/zjc/abaw/dataset/MAFW/data/frames/frames'\n",
    "\n",
    "for emo, clips in emoclip.items():\n",
    "\n",
    "    os.makedirs(os.path.join(mafwce, emo), exist_ok=True)\n",
    "    for clip in clips:\n",
    "        org_path = os.path.join(frame_path, clip[:-4])\n",
    "        tgt_path = os.path.join(mafwce, emo, clip[:-4])\n",
    "        shutil.copytree(org_path, tgt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.load('manet/[02-08]-[21-19]-model_best-acc88.33.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load('mafwanno.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "with open('output/2024-03-16-004208/train.log', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "lines = [float(line.strip().split(' ')[-1]) for line in lines if 'loss ' in line]\n",
    "plt.plot(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "checkpoint = torch.load('resnetferplus/best_bak_unity.pth')\n",
    "pre_trained_dict = {k.replace('module.', ''): v for k,v in checkpoint.items()}\n",
    "\n",
    "pre_trained_dict.pop('classifier.weight')\n",
    "pre_trained_dict.pop('classifier.bias')\n",
    "torch.save(pre_trained_dict, 'resnetferplus/ferplus/resnet50_ferplus_dag.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = []\n",
    "\n",
    "for i in (glob('dataset/MAFWCE7/*/*')):\n",
    "    ls.append(len(os.listdir(i)))\n",
    "\n",
    "from collections import Counter\n",
    "Counter(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import torch\n",
    "import numpy as np\n",
    "true, pred = torch.load('rafdb_ense_pred.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7460161465490849"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(true, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 23   0   5   4   6   0   0]\n",
      " [  4  22   5   1   0   0   3]\n",
      " [  2   2  98  12   1   1   0]\n",
      " [  3   2   4 123   1   1   1]\n",
      " [  1   1   0   0  27   4   0]\n",
      " [  0   0   2   1   0  17   2]\n",
      " [  0   1   2   2   0   2  11]]\n",
      "397\n",
      "60.526315789473685\n",
      "62.857142857142854\n",
      "84.48275862068965\n",
      "91.11111111111111\n",
      "81.81818181818181\n",
      "77.27272727272727\n",
      "61.111111111111114\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(true, pred)\n",
    "print(cm)\n",
    "print(cm.sum())\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(cm)):\n",
    "    print(cm[i][i] * 100 / cm.sum(axis=-1)[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "a, b, c,d = torch.load('predication/pred.pth',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('mae/output_dir_base/checkpoint-0.pth')['model']['head.bias'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
